{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash   Magnesium  \\\n",
       "0      1    14.23        1.71  2.43                15.6        127   \n",
       "1      1    13.20        1.78  2.14                11.2        100   \n",
       "2      1    13.16        2.36  2.67                18.6        101   \n",
       "3      1    14.37        1.95  2.50                16.8        113   \n",
       "4      1    13.24        2.59  2.87                21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing Wine Data and adding columns' names\n",
    "df = pd.read_csv(\"wine.data\", header=None, \n",
    "                 names=['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash ', 'Magnesium', 'Total phenols',\n",
    "                        'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue',\n",
    "                        'OD280/OD315 of diluted wines', 'Proline'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash   Magnesium  \\\n",
       "0      1    14.23        1.71  2.43                15.6        127   \n",
       "1      1    13.20        1.78  2.14                11.2        100   \n",
       "2      1    13.16        2.36  2.67                18.6        101   \n",
       "3      1    14.37        1.95  2.50                16.8        113   \n",
       "4      1    13.24        2.59  2.87                21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace if NaN\n",
    "\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Rows and Columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "# Selecting Data\n",
    "wineAttr = df.loc[:, df.columns != 'Class'].astype(float)\n",
    "wineClass = df[\"Class\"]\n",
    "\n",
    "# Scaling Data\n",
    "wineAttrScaled = scale.fit_transform(wineAttr[wineAttr.columns].values)\n",
    "\n",
    "wineAttrScaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Separate data por train and test unscaled\n",
    "Wine_train, Wine_test, Class_train, Class_test = train_test_split(wineAttr, wineClass, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7312571300764876"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multivariate Regression\n",
    "\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "multi = TheilSenRegressor(random_state=0).fit(Wine_train, Class_train)\n",
    "\n",
    "multi.score(Wine_test, Class_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06272541310529027"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with Cross Validation\n",
    "\n",
    "scores = cross_val_score(multi, wineAttr, wineClass, cv=10)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611111111111112"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(Wine_train, Class_train)\n",
    "\n",
    "nb.score(Wine_test, Class_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507675438596491"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with Cross Validation\n",
    "\n",
    "scores = cross_val_score(nb, wineAttr, wineClass, cv=10)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data por train and test scaled\n",
    "Wine_train, Wine_test, Class_train, Class_test = train_test_split(wineAttrScaled, wineClass, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel='poly',degree=3, C=1, gamma='auto').fit(Wine_train, Class_train)\n",
    "\n",
    "svc.score(Wine_test, Class_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502579979360165"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with Cross Validation\n",
    "\n",
    "scores = cross_val_score(svc, wineAttrScaled, wineClass, cv=10)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(10)\n",
    "knn.fit(Wine_train, Class_train)\n",
    "knn.score(Wine_test, Class_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666322669418644"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check with Cross Validation\n",
    "\n",
    "scores = cross_val_score(knn, wineAttrScaled, wineClass, cv=10)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_shape=(13,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142 samples, validate on 36 samples\n",
      "Epoch 1/150\n",
      " - 2s - loss: 1.6099 - acc: 0.1972 - val_loss: 1.5737 - val_acc: 0.1111\n",
      "Epoch 2/150\n",
      " - 0s - loss: 1.5562 - acc: 0.3099 - val_loss: 1.5148 - val_acc: 0.1389\n",
      "Epoch 3/150\n",
      " - 0s - loss: 1.4623 - acc: 0.2887 - val_loss: 1.4709 - val_acc: 0.1667\n",
      "Epoch 4/150\n",
      " - 0s - loss: 1.4212 - acc: 0.3521 - val_loss: 1.4338 - val_acc: 0.1944\n",
      "Epoch 5/150\n",
      " - 0s - loss: 1.3912 - acc: 0.3803 - val_loss: 1.4004 - val_acc: 0.2500\n",
      "Epoch 6/150\n",
      " - 0s - loss: 1.3706 - acc: 0.3803 - val_loss: 1.3651 - val_acc: 0.3333\n",
      "Epoch 7/150\n",
      " - 0s - loss: 1.2809 - acc: 0.5070 - val_loss: 1.3327 - val_acc: 0.3611\n",
      "Epoch 8/150\n",
      " - 0s - loss: 1.2544 - acc: 0.5070 - val_loss: 1.3000 - val_acc: 0.4167\n",
      "Epoch 9/150\n",
      " - 0s - loss: 1.2488 - acc: 0.4648 - val_loss: 1.2638 - val_acc: 0.5278\n",
      "Epoch 10/150\n",
      " - 0s - loss: 1.1977 - acc: 0.5282 - val_loss: 1.2304 - val_acc: 0.5833\n",
      "Epoch 11/150\n",
      " - 0s - loss: 1.1314 - acc: 0.5634 - val_loss: 1.1966 - val_acc: 0.6389\n",
      "Epoch 12/150\n",
      " - 0s - loss: 1.0533 - acc: 0.6197 - val_loss: 1.1642 - val_acc: 0.6389\n",
      "Epoch 13/150\n",
      " - 0s - loss: 1.1062 - acc: 0.5493 - val_loss: 1.1269 - val_acc: 0.6667\n",
      "Epoch 14/150\n",
      " - 0s - loss: 1.0612 - acc: 0.6056 - val_loss: 1.0889 - val_acc: 0.6667\n",
      "Epoch 15/150\n",
      " - 0s - loss: 1.0239 - acc: 0.6338 - val_loss: 1.0525 - val_acc: 0.7500\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.9487 - acc: 0.6761 - val_loss: 1.0184 - val_acc: 0.7778\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.9313 - acc: 0.7042 - val_loss: 0.9797 - val_acc: 0.7778\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.8963 - acc: 0.6761 - val_loss: 0.9459 - val_acc: 0.7778\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.8325 - acc: 0.7324 - val_loss: 0.9137 - val_acc: 0.7778\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.7915 - acc: 0.7958 - val_loss: 0.8792 - val_acc: 0.7778\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.8474 - acc: 0.6972 - val_loss: 0.8369 - val_acc: 0.7778\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.7848 - acc: 0.7113 - val_loss: 0.7984 - val_acc: 0.7778\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.6624 - acc: 0.8169 - val_loss: 0.7618 - val_acc: 0.7778\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.6683 - acc: 0.8169 - val_loss: 0.7201 - val_acc: 0.7778\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.6896 - acc: 0.8169 - val_loss: 0.6880 - val_acc: 0.7778\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.6402 - acc: 0.8732 - val_loss: 0.6552 - val_acc: 0.8056\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.6176 - acc: 0.8099 - val_loss: 0.6263 - val_acc: 0.8056\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.5757 - acc: 0.8310 - val_loss: 0.5956 - val_acc: 0.8056\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.5688 - acc: 0.8239 - val_loss: 0.5705 - val_acc: 0.8056\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.5282 - acc: 0.8451 - val_loss: 0.5473 - val_acc: 0.8333\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.6016 - acc: 0.7746 - val_loss: 0.5242 - val_acc: 0.8333\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.5338 - acc: 0.8169 - val_loss: 0.5067 - val_acc: 0.8611\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.4543 - acc: 0.8310 - val_loss: 0.4832 - val_acc: 0.8611\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.4514 - acc: 0.8873 - val_loss: 0.4589 - val_acc: 0.8611\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.4558 - acc: 0.8803 - val_loss: 0.4372 - val_acc: 0.8611\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.4328 - acc: 0.8592 - val_loss: 0.4153 - val_acc: 0.8889\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.4137 - acc: 0.8873 - val_loss: 0.3970 - val_acc: 0.8889\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.4148 - acc: 0.8451 - val_loss: 0.3790 - val_acc: 0.8889\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.3953 - acc: 0.8732 - val_loss: 0.3635 - val_acc: 0.8889\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.4006 - acc: 0.8803 - val_loss: 0.3494 - val_acc: 0.8889\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.4145 - acc: 0.8662 - val_loss: 0.3346 - val_acc: 0.8889\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.4305 - acc: 0.8592 - val_loss: 0.3213 - val_acc: 0.8889\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.3633 - acc: 0.8803 - val_loss: 0.3092 - val_acc: 0.8889\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.3792 - acc: 0.8380 - val_loss: 0.2958 - val_acc: 0.8889\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.3464 - acc: 0.9014 - val_loss: 0.2857 - val_acc: 0.8889\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.3457 - acc: 0.8873 - val_loss: 0.2807 - val_acc: 0.8889\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.3645 - acc: 0.9014 - val_loss: 0.2729 - val_acc: 0.8889\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.3155 - acc: 0.9437 - val_loss: 0.2640 - val_acc: 0.8889\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.3181 - acc: 0.8944 - val_loss: 0.2583 - val_acc: 0.8889\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.3542 - acc: 0.8521 - val_loss: 0.2506 - val_acc: 0.9167\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.3336 - acc: 0.9225 - val_loss: 0.2432 - val_acc: 0.9167\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.3622 - acc: 0.8873 - val_loss: 0.2366 - val_acc: 0.9167\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.3266 - acc: 0.9014 - val_loss: 0.2333 - val_acc: 0.9167\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.2730 - acc: 0.9366 - val_loss: 0.2271 - val_acc: 0.9167\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.2750 - acc: 0.9225 - val_loss: 0.2201 - val_acc: 0.9167\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.3242 - acc: 0.8944 - val_loss: 0.2167 - val_acc: 0.9167\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.3225 - acc: 0.9085 - val_loss: 0.2116 - val_acc: 0.9167\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.2865 - acc: 0.9225 - val_loss: 0.2036 - val_acc: 0.9167\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.3195 - acc: 0.9507 - val_loss: 0.1915 - val_acc: 0.9167\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.2879 - acc: 0.9296 - val_loss: 0.1847 - val_acc: 0.9167\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.2505 - acc: 0.9507 - val_loss: 0.1802 - val_acc: 0.9167\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.2959 - acc: 0.9225 - val_loss: 0.1739 - val_acc: 0.9167\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.2499 - acc: 0.9437 - val_loss: 0.1684 - val_acc: 0.9167\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.2965 - acc: 0.9085 - val_loss: 0.1677 - val_acc: 0.9167\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.2477 - acc: 0.9437 - val_loss: 0.1641 - val_acc: 0.9167\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.2076 - acc: 0.9718 - val_loss: 0.1618 - val_acc: 0.9167\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.2385 - acc: 0.9296 - val_loss: 0.1547 - val_acc: 0.9167\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.2100 - acc: 0.9507 - val_loss: 0.1514 - val_acc: 0.9167\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.2658 - acc: 0.9366 - val_loss: 0.1499 - val_acc: 0.9167\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.3547 - acc: 0.8803 - val_loss: 0.1462 - val_acc: 0.9167\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.2797 - acc: 0.9366 - val_loss: 0.1417 - val_acc: 0.9167\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.2551 - acc: 0.9155 - val_loss: 0.1382 - val_acc: 0.9167\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.2259 - acc: 0.9648 - val_loss: 0.1358 - val_acc: 0.9167\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.2540 - acc: 0.9225 - val_loss: 0.1336 - val_acc: 0.9167\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.2154 - acc: 0.9437 - val_loss: 0.1322 - val_acc: 0.9167\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.2635 - acc: 0.9085 - val_loss: 0.1327 - val_acc: 0.9167\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.2088 - acc: 0.9577 - val_loss: 0.1310 - val_acc: 0.9167\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.2542 - acc: 0.9155 - val_loss: 0.1280 - val_acc: 0.9167\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.2138 - acc: 0.9507 - val_loss: 0.1249 - val_acc: 0.9167\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.1989 - acc: 0.9507 - val_loss: 0.1229 - val_acc: 0.9167\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.2332 - acc: 0.9366 - val_loss: 0.1207 - val_acc: 0.9167\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.1840 - acc: 0.9648 - val_loss: 0.1146 - val_acc: 0.9444\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.2320 - acc: 0.9577 - val_loss: 0.1119 - val_acc: 0.9722\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.1999 - acc: 0.9437 - val_loss: 0.1093 - val_acc: 0.9722\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.2807 - acc: 0.9155 - val_loss: 0.1073 - val_acc: 0.9722\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.2420 - acc: 0.9225 - val_loss: 0.1040 - val_acc: 0.9722\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.2320 - acc: 0.9366 - val_loss: 0.1003 - val_acc: 0.9722\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.1902 - acc: 0.9577 - val_loss: 0.0966 - val_acc: 0.9722\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.2458 - acc: 0.9296 - val_loss: 0.0947 - val_acc: 0.9722\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.1606 - acc: 0.9648 - val_loss: 0.0932 - val_acc: 0.9722\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.1988 - acc: 0.9577 - val_loss: 0.0921 - val_acc: 0.9722\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.1951 - acc: 0.9507 - val_loss: 0.0892 - val_acc: 0.9722\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.2240 - acc: 0.9507 - val_loss: 0.0872 - val_acc: 0.9722\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.2555 - acc: 0.9225 - val_loss: 0.0843 - val_acc: 0.9722\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.2136 - acc: 0.9296 - val_loss: 0.0824 - val_acc: 0.9722\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.2289 - acc: 0.9577 - val_loss: 0.0820 - val_acc: 0.9722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150\n",
      " - 0s - loss: 0.1993 - acc: 0.9437 - val_loss: 0.0813 - val_acc: 0.9722\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.2100 - acc: 0.9648 - val_loss: 0.0812 - val_acc: 0.9722\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.1922 - acc: 0.9366 - val_loss: 0.0809 - val_acc: 0.9722\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.2276 - acc: 0.9437 - val_loss: 0.0815 - val_acc: 0.9722\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.1554 - acc: 0.9648 - val_loss: 0.0804 - val_acc: 0.9722\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.1839 - acc: 0.9437 - val_loss: 0.0788 - val_acc: 0.9722\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.2304 - acc: 0.9366 - val_loss: 0.0750 - val_acc: 0.9722\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.1389 - acc: 0.9577 - val_loss: 0.0737 - val_acc: 0.9722\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.1761 - acc: 0.9648 - val_loss: 0.0724 - val_acc: 0.9722\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.2458 - acc: 0.9225 - val_loss: 0.0704 - val_acc: 0.9722\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.1707 - acc: 0.9507 - val_loss: 0.0676 - val_acc: 0.9722\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.2048 - acc: 0.9507 - val_loss: 0.0660 - val_acc: 0.9722\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.1935 - acc: 0.9437 - val_loss: 0.0652 - val_acc: 0.9722\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.1427 - acc: 0.9648 - val_loss: 0.0637 - val_acc: 0.9722\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.1839 - acc: 0.9437 - val_loss: 0.0620 - val_acc: 0.9722\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.1935 - acc: 0.9648 - val_loss: 0.0614 - val_acc: 0.9722\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.2265 - acc: 0.9225 - val_loss: 0.0608 - val_acc: 0.9722\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.1846 - acc: 0.9648 - val_loss: 0.0603 - val_acc: 0.9722\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.1790 - acc: 0.9577 - val_loss: 0.0596 - val_acc: 0.9722\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.1935 - acc: 0.9366 - val_loss: 0.0597 - val_acc: 0.9722\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.1851 - acc: 0.9507 - val_loss: 0.0584 - val_acc: 0.9722\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.1656 - acc: 0.9437 - val_loss: 0.0572 - val_acc: 0.9722\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.1698 - acc: 0.9507 - val_loss: 0.0556 - val_acc: 0.9722\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.1570 - acc: 0.9577 - val_loss: 0.0547 - val_acc: 0.9722\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.1767 - acc: 0.9507 - val_loss: 0.0543 - val_acc: 1.0000\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.1443 - acc: 0.9789 - val_loss: 0.0542 - val_acc: 1.0000\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.1918 - acc: 0.9648 - val_loss: 0.0535 - val_acc: 1.0000\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.1300 - acc: 0.9859 - val_loss: 0.0529 - val_acc: 1.0000\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.1441 - acc: 0.9648 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.1434 - acc: 0.9718 - val_loss: 0.0515 - val_acc: 1.0000\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.1809 - acc: 0.9507 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.1571 - acc: 0.9577 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.1338 - acc: 0.9648 - val_loss: 0.0513 - val_acc: 1.0000\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.1270 - acc: 0.9718 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.1083 - acc: 0.9718 - val_loss: 0.0498 - val_acc: 1.0000\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.1325 - acc: 0.9789 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.1750 - acc: 0.9577 - val_loss: 0.0480 - val_acc: 1.0000\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.1426 - acc: 0.9859 - val_loss: 0.0466 - val_acc: 1.0000\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.1092 - acc: 0.9789 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.1920 - acc: 0.9577 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.0990 - acc: 0.9789 - val_loss: 0.0450 - val_acc: 1.0000\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.1381 - acc: 0.9718 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.1603 - acc: 0.9507 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.1532 - acc: 0.9577 - val_loss: 0.0428 - val_acc: 1.0000\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.1429 - acc: 0.9648 - val_loss: 0.0420 - val_acc: 1.0000\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.1159 - acc: 0.9718 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.1300 - acc: 0.9789 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.1356 - acc: 0.9577 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.1304 - acc: 0.9718 - val_loss: 0.0400 - val_acc: 1.0000\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.1303 - acc: 0.9789 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.1026 - acc: 0.9789 - val_loss: 0.0388 - val_acc: 1.0000\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.1088 - acc: 0.9789 - val_loss: 0.0385 - val_acc: 1.0000\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.1675 - acc: 0.9718 - val_loss: 0.0381 - val_acc: 1.0000\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.1378 - acc: 0.9577 - val_loss: 0.0378 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4381b5588>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Wine_train, Class_train,\n",
    "          batch_size=10,\n",
    "          epochs=150,\n",
    "          verbose=2,\n",
    "          validation_data=(Wine_test, Class_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
